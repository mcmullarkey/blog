---
title: "Party Drugs, Lies, and Statistics"
description: |
  How the party drug hype cycle is both already over and neverending
author:
  - name: Michael Mullarkey, PhD (Click to return to my website)
    url: https://mcmullarkey.github.io
date: 05-04-2021
output:
  distill::distill_article:
    self_contained: false
draft: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(pwr)

```

# I: Pretending

Let's pretend the hype cycle of "party drugs are miracle mental health drugs!" is already over. This time wasn't different. The rates of mental health problems are either staying unacceptably high or climbing even higher. The well-intentioned^[Or maybe not, who knows] scientists, once hopeful patients, opportunistic grifters, and bored VCs have all moved on to the next big thing. <br>
<br>
How could we have gotten here? <br>
<br>
After all, there was just [a New York Times writeup](https://t.co/geXhhVe2w8?amp=1){target="_blank"} of a gold-standard, placebo-controlled trial showing MDMA improved PTSD! The headline even says "A Psychedelic Drug Passes Big Test for PTSD treatment." There have been a lot of other promising headlines too, like ["Could the Embrace of Psychedelics Lead to a Mental-Health Revolution?"](https://www.vogue.com/article/psychededlic-wellness-mental-health){target="_blank"}, ["Mind Menders: The Future of Psychedelics for Mental Illness"](https://www.medscape.com/viewarticle/940749){target="_blank"}, and ["How ecstasy and psilocybin are shaking up psychiatry."](https://www.nature.com/articles/d41586-021-00187-9){target="_blank"} That last headline is from Nature. <br>
<br>
Humans are bad at predicting the future. But if the party drug hype cycle ends, a lot of its downfall could be predicted by one of the first skills we develop.

# II: Counting

There's a [great statistics textbook](https://xcelab.net/rm/statistical-rethinking/){target="_blank"} I'm slogging my way through right now. A lot of its insights have come from translating scientific jargon into actionable English. At many points throughout, the author reminds us statistics is glorified counting.^[The author is making a specific, technical point in the context of Bayesian statistics, and I think the general principle is still useful]<br>
<br>
Let's do some counting with the latest, greatest party drug trial. From the NYT article, "67 percent of participants in the MDMA group no longer qualified for a diagnosis of PTSD, compared with 32 percent in the placebo group." That sounds super impressive! But percentages aren't quite counting yet.<br>
<br>
There were 90 people in the trial, so let's assume an equal number of people in both groups and that literally no one left the study.^[That seems unlikely, but let's give the study the benefit of the doubt] That means ~30 out of 45 people who took MDMA got better, while ~15 out of 45 people who took an inactive placebo got better.<br>
<br>
I'm over the moon for the ~45 folks who got better during this study, including ~30 of them who did so in the group who took MDMA. And if you're also asking "Wait, only a high school classroom's worth of people got better with MDMA? Is that enough to decide a drug works?" your instincts are right.

# III: Powering

Part of the alchemy that turns counting into helpful statistics is having enough stuff to count. Every single person's life is valuable beyond measure. In a randomized trial of a treatment each person counts exactly once.^[Unless you have lots of repeated measures from individual people, but that's just a different, more complicated kind of counting] We can do a power analysis --- a formula that tells us how many people we need to trust our counting process --- to figure out if the party drug trial had enough stuff to count. <br>
<br>
When we run this formula and assume party drugs have effects similar to psychotherapy and other psychotropic medications^[Using d = 0.20 as an approximation from low risk of bias, higher sample size trials testing these treatments, see <https://www.ncbi.nlm.nih.gov/books/NBK78732/>, assuming the placebo response rate was equivalent to what was observed in the trial, and only giving ourselves a 5% chance of a false negative] we find this trial had nowhere near enough stuff to count. The study would need to be ~100 times larger for us to take the counts seriously.

```{r}

## Getting odds ratios based on this formula https://www.ncbi.nlm.nih.gov/books/NBK431098/

obs_odds_ratio <- (30/15)/(15/30) 

obs_d <- log(obs_odds_ratio) / 1.81 # Based on this article https://onlinelibrary.wiley.com/doi/10.1002/1097-0258(20001130)19:22%3C3127::AID-SIM784%3E3.0.CO;2-M

# Figuring out odds ratio equivalent to d = 0.20 (small effect)

small_or <- (0.20 * 1.81)^exp(1)

odds_treat <- (small_or * 0.5)

small_odds_ratio <- (183/267)/(150/300) 

# For a small effect

p.out_small <- pwr.p.test(h = ES.h(p1 = 0.3616, p2 = 0.33),
                    sig.level = 0.05,
                    power = 0.95)
plot(p.out_small) +
  labs(title = "How Many People Do We Need to Detect a 'Normal' Treatment Effect?") 

```
If, however, we assume MDMA is twice as powerful as any other high-quality intervention we've ever seen, there's more than enough stuff to count. We'd only have count up the responses of 78 folks to know reliably how well people responded to MDMA.

```{r}

# Figuring out odds ratio equivalent to d = 0.40 (double a small effect)

small_or <- (0.40 * 1.81)^exp(1)

odds_treat <- (small_or * 0.5)

# For double a small effect

p.out_double <- pwr.p.test(h = ES.h(p1 = 0.5308, p2 = 0.33),
                    sig.level = 0.05,
                    power = 0.95)
plot(p.out_double) +
  labs(title = "How Many People Do We Need to Detect Double That Effect?")

```

## IV: Pretending Again

Now, we're back to pretending the party drug hype cycle is over. It's obvious now we shouldn't have expected these drugs to be twice as powerful as anything we've tested before. Sure, the smaller studies showed much larger effects, [as they always do](https://www.sciencedirect.com/science/article/pii/S089543561500164X){target="_blank"}. But in this world we conducted much larger trials next, and the apparent benefits shrank or disappeared. Or we never conducted larger trials, but it's been years to decades with no obvious improvement in overall mental health. <br>
<br>
We're looking back with disgust at the [enrollment of patients into studies without telling them](https://www.nature.com/articles/d41586-018-05805-7){target="_blank"}, nodding knowingly about the [many documented, non-counting related flaws in the "above board" studies](https://twitter.com/mcmullarkey/status/1084560787639803905?s=20){target="_blank"}, and already hoping the next hyped treatment will succeed where party drugs have failed. The New York Times has even written an excellent investigative piece tying together everything that went wrong. The people they interview who are still suffering break our hearts.

## V: Hoping

I hope the world where the party drug hype cycle ends is only a fantasy. I hope against hope, despite no good evidence, that party drugs are twice as effective (or more) as anything we already have. I'm human, I hope for a lot of things that probably aren't true.

